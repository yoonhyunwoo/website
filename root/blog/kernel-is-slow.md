커널의 네트워크 스택은 상대적으로 느리다고 평가됩니다. IT 분야에 있다면 이런 이야기를 여러 번 들어봤을 것입니다.
이 때문에 고성능 네트워크 처리가 필요한 기업에서는 커널의 네트워크 스택을 거치지 않고, eBPF 등을 활용해 커널 진입 이전 단계에서 패킷을 처리하기도 합니다.

그러나 이러한 방식은 구현과 운영 모두에서 많은 비용이 듭니다. 개발자와 운영자는 새로운 네트워크 처리 방식을 이해해야 하며, 처리 과정이 복잡해질수록 관리 부담도 커집니다. 따라서 많은 경우 커널 파라미터 튜닝을 통해 성능 요구사항을 충족합니다. 이러한 튜닝 방법은 Red Hat의 Linux 성능 최적화 오픈소스 프로젝트인 [redhat-performance/tuned](https://github.com/redhat-performance/tuned)혹은 각 기업의 기술블로그등에서 확인할 수 있습니다.

본 글에서는 커널 네트워크 스택에서 병목이 발생할 수 있는 주요 지점을 살펴보고, 이를 관측하는 방법을 다룹니다.
NIC(Network Interface Card) 오프로딩 등 커널 외부 영역은 범위에서 제외하며, 커널 내부의 처리 과정을 중심으로 설명합니다.
진행 순서는 OSI 7Layer 순으로 구성됩니다. 드라이버의 경우에는 벤더사별로 다른 관계로 여기서는 다루지 않습니다. 또한 커널 버전 v6.17.6을 기준으로 합니다.

# L2 (Ethernet)

저는 프로그램을 데이터 변환 과정으로 설명하는 방식을 선호합니다. 개발이란 결국 데이터를 처리하고 가공하는 일련의 과정이기 때문입니다.

Ethernet 스택은 NIC가 전달한 소켓 버퍼(skb)를 L3 IP 레이어가 이해할 수 있는 형태로 변환하는 과정입니다. NIC가 전달해준 프레임은 처음에는 IRQ(Interrupt Request), 이후에는 NAPI poll 과정을 통해 sk_buff인스턴스로 가공되고 여기에 필요한 메타데이터를 추가하게 됩니다.

일반적으로 커널 내에서 소켓 버퍼는 다음과 같이 처리됩니다.
```
netif_receive_skb()
  └─ netif_receive_skb_internal()
       └─ __netif_receive_skb()
            └─ __netif_receive_skb_one_core()
```

이 과정에서 커널은 CPU 분배, 타임스탬프 처리 등 L2 단계에서 필요한 작업을 수행한 뒤 데이터를 IP 계층으로 전달합니다. 이후 ip_rcv를 호출하기 전에 RX qdisc를 거치며, 이 단계에서 이더넷 레이어의 sk_buff 인스턴스를 활용해 BPF 처리 등 가상의 큐잉 동작이 수행됩니다. 병목지점과 튜닝포인트를 찾는 글이기에 자세한 설명은 수행하지 않습니다. 

> RX와 TX는 각각 Receive(수신)와 Transmit(송신)을 의미하며, TX, RX의 `X`는 `Trans`의 약자입니다.
